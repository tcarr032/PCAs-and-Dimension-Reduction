{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "m = 60\n",
    "X = np.zeros((m, 3))  # initialize 3D dataset\n",
    "np.random.seed(42)\n",
    "angles = (np.random.rand(m) ** 3 + 0.5) * 2 * np.pi  # uneven distribution\n",
    "X[:, 0], X[:, 1] = np.cos(angles), np.sin(angles) * 0.5  # oval\n",
    "X += 0.28 * np.random.randn(m, 3)  # add more noise\n",
    "X = Rotation.from_rotvec([np.pi / 29, -np.pi / 20, np.pi / 4]).apply(X)\n",
    "X += [0.2, 0, 0.2]  # shift a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1: [0.67857588 0.70073508 0.22023881]\n",
      "c2: [-0.72817329  0.6811147   0.07646185]\n"
     ]
    }
   ],
   "source": [
    "X_centered = X - X.mean(axis=0)\n",
    "\n",
    "U, s, Vt = np.linalg.svd(X_centered)\n",
    "c1 = Vt[0]\n",
    "c2 = Vt[1]\n",
    "print(f'c1: {c1}')\n",
    "print(f'c2: {c2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c1 and c2 are unit vector for each of the pricpal components for the 3D dataset\n",
    "\n",
    "This can then be projected onto a hyperplane to tranform it to 2D space or d-space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old shape: (60, 3)\n",
      "new shape: (60, 2)\n"
     ]
    }
   ],
   "source": [
    "W2 = Vt[:2].T\n",
    "X2D = X_centered @ W2\n",
    "print(f'old shape: {X_centered.shape}')\n",
    "print(f'new shape: {X2D.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 rows without sklearn:\n",
      " [[-0.87323119 -0.29459803]\n",
      " [ 0.14888518  0.51493557]\n",
      " [ 1.35121872 -0.39950155]\n",
      " [ 0.45436676 -0.1399845 ]\n",
      " [-0.73438909 -0.02289346]]\n",
      "first 5 rows with sklearn:\n",
      " [[-0.87323119  0.29459803]\n",
      " [ 0.14888518 -0.51493557]\n",
      " [ 1.35121872  0.39950155]\n",
      " [ 0.45436676  0.1399845 ]\n",
      " [-0.73438909  0.02289346]]\n"
     ]
    }
   ],
   "source": [
    "#With sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "print(f'first 5 rows without sklearn:\\n {X2D[:5,:]}')\n",
    "X2D = pca.fit_transform(X_centered)\n",
    "print(f'first 5 rows with sklearn:\\n {X2D[:5,:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.67857588,  0.70073508,  0.22023881],\n",
       "       [ 0.72817329, -0.6811147 , -0.07646185]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7578477 , 0.15186921])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "mnist = fetch_openml('mnist_784', as_frame=False)\n",
    "X_train, X_test = mnist.data[:60000], mnist.data[60_000:]\n",
    "y_train, y_test = mnist.target[:60000], mnist.target[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cumsum >= 0.95) + 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('pca', PCA(random_state=42)),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier(random_state=42))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'pca__n_components': array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26,\n",
       "       27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43,\n",
       "       44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,...\n",
       "       414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426,\n",
       "       427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439,\n",
       "       440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452,\n",
       "       453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "       466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
       "       479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491,\n",
       "       492, 493, 494, 495, 496, 497, 498, 499])},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "clf = make_pipeline(PCA(random_state=42), RandomForestClassifier(random_state=42))\n",
    "\n",
    "params = {\n",
    "    \"pca__n_components\": np.arange(10,80),\n",
    "    \"randomforestclassifier__n_estimators\": np.arange(50,500)\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(clf, params, cv=3, n_iter=10, n_jobs=-1, random_state=42)\n",
    "rnd_search.fit(X_train[:1000], y_train[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=23, random_state=42)),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(n_estimators=465, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.93258864, -312.67426198,  -24.51405174, ...,  -62.00213296,\n",
       "          -8.8147422 ,  -66.93993166],\n",
       "       [1011.71837586, -294.85703831,  596.33956108, ...,  -24.52514836,\n",
       "          26.58534428,   16.99077095],\n",
       "       [ -51.84960804,  392.17315289, -188.50974941, ...,   -8.99144972,\n",
       "          -2.99473092,   56.93622984],\n",
       "       ...,\n",
       "       [-178.0534496 ,  160.0782111 , -257.61308227, ...,   35.30439525,\n",
       "          -2.75142691,   23.97581712],\n",
       "       [ 130.60607212,   -5.59193632,  513.85867376, ...,  -15.84132904,\n",
       "         -18.38612585,   39.40742042],\n",
       "       [-173.43595246,  -24.71880228,  556.01889398, ...,   29.62816702,\n",
       "         -52.61652274,   27.99524134]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_pca = PCA(n_components=154, svd_solver='randomized', random_state=42)\n",
    "X_reduced = rnd_pca.fit_transform(X_train)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 123.93240015,  312.67412765,   24.51396855, ...,   55.02414967,\n",
       "         -18.82319306,   57.12605157],\n",
       "       [1011.71883902,  294.85791533, -596.3396284 , ...,   40.79115354,\n",
       "         -28.52753525,  -32.93944347],\n",
       "       [ -51.84977972, -392.17395257,  188.50798593, ...,   18.5109603 ,\n",
       "         -75.96611653,   -7.67736302],\n",
       "       ...,\n",
       "       [-178.0534095 , -160.07838721,  257.61233558, ...,  -57.3811145 ,\n",
       "           6.70673288,  -54.26797595],\n",
       "       [ 130.60654125,    5.59174593, -513.85834969, ...,  -22.43044205,\n",
       "          12.51568244,  -36.3004746 ],\n",
       "       [-173.43566358,   24.71937319, -556.01892138, ...,  -48.33215133,\n",
       "          19.2936437 ,  -30.58306681]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "n_batches = 100\n",
    "inc_pca = IncrementalPCA(n_components=154)\n",
    "for X_batch in np.array_split(X_train, n_batches):\n",
    "    inc_pca.partial_fit(X_batch)\n",
    "X_reduced = inc_pca.transform(X_train)\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_mnist.mmap\"\n",
    "X_mmap = np.memmap(filename, dtype='float32', mode='write', shape=X_train.shape)\n",
    "X_mmap[:] = X_train\n",
    "X_mmap.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mmap = np.memmap(filename, dtype='float32', mode='readonly').reshape(-1,784)\n",
    "batch_size = X_mmap.shape[0] #n_batches\n",
    "inc_pca = IncrementalPCA(n_components=154, batch_size=batch_size)\n",
    "inc_pca.fit(X_mmap)\n",
    "inc_pca.batch_size_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mmap.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca9c90c9b299e3c35d28bc96236d8f2c0bd3d51256cb5ad616950692d4a1a879"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
